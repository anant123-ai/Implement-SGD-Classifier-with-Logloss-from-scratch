{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2S-uFqwSvmg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUxLkBjISvmr"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xexp5GYNSvmz",
    "outputId": "fa6ffd4e-02ef-45c9-b26e-906f2ebe0016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54vJVc_KSvm9"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pKAn1-ASvm_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r97pFTgrSvnE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jykLIXZNSvnJ",
    "outputId": "fc334b23-cfa4-4408-92c4-d59babe4be6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0-M6oXASvnO"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sShoMeocSvnP"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "gm6wi8L2SvnU",
    "outputId": "5b1a72cb-5fbd-459a-931a-6c78f1d5c78b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "Q4WFoxgASvnc",
    "outputId": "2d62fd04-f2cd-411e-b906-a0576bd4f6d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.08 seconds.\n",
      "Convergence after 10 epochs took 0.08 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7WaVxhGpSvnj",
    "outputId": "63c78d59-637b-41d2-9d32-8298f314258d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Su9e8fRLSvno"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcz5_UqCSvnq"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOBvEchCSvnr"
   },
   "source": [
    "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xbn61rrXSvnt"
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14bA5yR3Svnv"
   },
   "source": [
    "- Load the datasets(train and test) into the respective arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7183hFBSvnv"
   },
   "source": [
    "- Initialize the weight_vector and intercept term randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdLeFU0USvnx"
   },
   "source": [
    "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEVtAlO1Svny"
   },
   "source": [
    "- for each epoch:\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
    "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
    "        $b^{(t+1)} ← (b^t +  α(y_n - σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
    "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qmRH4UpSvny"
   },
   "source": [
    "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbZf9p5gSvn1"
   },
   "source": [
    "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Fpz8X5DMSvn2",
    "outputId": "b1945289-e53a-4160-8dc6-c16b1fcb9358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros_like(X_train[0])\n",
    "b = 0\n",
    "eta0 = 0.0001\n",
    "alpha = 0.0001\n",
    "N = len(X_train)\n",
    "print(len(X_train[0]))\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6Y5kVscSvn5"
   },
   "outputs": [],
   "source": [
    "#here is the sigmoid function\n",
    "def sigmoid(x,w,b):\n",
    "  z = np.dot(x,w.T)+b\n",
    "  return 1.0/(1+np.exp(-z))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XUfucUi89x7"
   },
   "outputs": [],
   "source": [
    "#here is the  log_loss function\n",
    "def log_loss(X,Y,W,B):\n",
    "    Sum=0\n",
    "    for i in range(0,len(X)):\n",
    "      y_score=sigmoid(X[i],W,B)\n",
    "      Sum=Sum+Y[i]*np.log(y_score)+(1-Y[i])*np.log(1-y_score)\n",
    "    return Sum*(-1/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GrMSqYpOQPWK",
    "outputId": "e887383b-629b-4bbc-e766-d836eda4e8a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intial_train_log_loss ==  0.6931471805594285\n",
      "intial_test_log_loss ==  0.6931471805600673\n"
     ]
    }
   ],
   "source": [
    "#calculating intial los_loss for train and test data.\n",
    "intial_train_log_loss =log_loss(X_train,y_train,w,b)\n",
    "intial_test_log_loss = log_loss(X_test,y_test,w,b)\n",
    "print(\"intial_train_log_loss == \",intial_train_log_loss)\n",
    "print(\"intial_test_log_loss == \",intial_test_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZBKrcnEHb-7N",
    "outputId": "4323449d-1115-4ef6-a0cb-15c3e6a1afc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train log_loss for epoch 0  ==  0.40403290750563464\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 0 == 0.4051787115691764\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 1  ==  0.388404070036009\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 1 == 0.390080701406506\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 2  ==  0.38314908600186265\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 2 == 0.3850248161373018\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 3  ==  0.3807878200398666\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 3 == 0.38274328047897416\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 4  ==  0.3796069876788165\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 4 == 0.38159369360985645\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 5  ==  0.37898511706106136\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 5 == 0.3809828931580255\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 6  ==  0.37864814221008164\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 6 == 0.3806487512719458\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 7  ==  0.37846236154083357\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 7 == 0.38046266423049313\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 8  ==  0.378358763362984\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 8 == 0.38035776536048627\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 9  ==  0.37830052188546714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 9 == 0.38029808814707217\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 10  ==  0.3782675741480116\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 10 == 0.38026387516983073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 11  ==  0.3782488384285893\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 11 == 0.38024412027243043\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 12  ==  0.3782381345869121\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 12 == 0.3802326309692096\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 13  ==  0.378231991551629\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 13 == 0.3802258965686224\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 14  ==  0.3782284491330998\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 14 == 0.3802219143378415\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 15  ==  0.3782263954690964\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 15 == 0.38021953547679066\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 16  ==  0.37822519749393685\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 16 == 0.38021809752952734\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 17  ==  0.3782244935019806\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 17 == 0.3802172164027742\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 18  ==  0.378224076120547\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 18 == 0.3802166680599804\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 19  ==  0.3782238260258433\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 19 == 0.38021632092120833\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 20  ==  0.37822367427659426\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 20 == 0.38021609707902754\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 21  ==  0.3782235808490689\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 21 == 0.3802159499590507\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 22  ==  0.3782235223727262\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 22 == 0.3802158513994314\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 23  ==  0.3782234851045095\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 23 == 0.3802157841437289\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train log_loss for epoch 24  ==  0.3782234608930447\n",
      "----------------------------------------------------------------------------------------------------\n",
      "test log_loss for epoch 24 == 0.3802157374558484\n",
      "----------------------------------------------------------------------------------------------------\n",
      "optomized w [-4.29657219e-01  1.92993106e-01 -1.48427055e-01  3.38103883e-01\n",
      " -2.21092230e-01  5.69863286e-01 -4.45184638e-01 -8.99472184e-02\n",
      "  2.21747438e-01  1.73749475e-01  1.98675572e-01 -5.17009955e-04\n",
      " -8.12587576e-02  3.39089377e-01  2.29658236e-02]\n",
      "optimized b -0.8912724453007421\n"
     ]
    }
   ],
   "source": [
    "# findind optimal w and b\n",
    "import random  \n",
    "Train_loss=[]\n",
    "Test_loss=[]\n",
    "for epoch in range(0,25):\n",
    "  \n",
    "  for i in range(0,N):\n",
    "      w = (1-((alpha*eta0)/N))*w+(alpha*X_train[i])*(y_train[i]-sigmoid(X_train[i],w,b))\n",
    "      b = b+(alpha)*(y_train[i]-sigmoid(X_train[i],w,b)) \n",
    "  \n",
    "  train_loss = log_loss(X_train,y_train,w,b)\n",
    "  print(\"train log_loss for epoch\",epoch,\" == \",train_loss)\n",
    "  Train_loss.append(train_loss)\n",
    "  test_loss = log_loss(X_test,y_test,w,b)\n",
    "  print('--'*50)\n",
    "  print(\"test log_loss for epoch\",epoch,\"==\",test_loss)\n",
    "  print(\"--\"*50)\n",
    "  Test_loss.append(test_loss)\n",
    "    \n",
    "\n",
    "print(\"optomized w\",w)\n",
    "print(\"optimized b\",b)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "DIsuSilI5gg-",
    "outputId": "22efe49d-0a96-4195-a42a-16a16823530d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot log_loss vs epoch\n",
    "import matplotlib.pyplot as plt\n",
    "a=list(range(0,25))\n",
    "plt.plot(a,Train_loss,label='Train_loss ')\n",
    "plt.plot(a,Test_loss,label='Test_loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.title(\"log_loss vs epoch\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Yy8jWaa7Svn_",
    "outputId": "9e143980-ea82-4d22-b135-d2e14b369585",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0062903 ,  0.00751745,  0.0001633 , -0.00334019, -0.01290553,\n",
       "          0.0096975 ,  0.00724019,  0.00414091,  0.01247424, -0.00709179,\n",
       "          0.00162367, -0.00473617, -0.00165506,  0.00056136,  0.00029861]]),\n",
       " array([-0.03813415]))"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "48gx6wQKSvoE",
    "outputId": "c45cff93-85ec-4261-bbed-460f2b3b2a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95224\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Logistic Regression using SGD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
